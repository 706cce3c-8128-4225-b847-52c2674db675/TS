{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: \n",
    "Реализовать дискретную версию SIR модели, в которой параметры зависят от номера дня и моделируются некоторыми вспомогательными функциями (эти функции могут зависеть от погоды, плотности населения и т.д.; далее будет рассмотрен случай, когда функции линейны), сравнить предсказания такой модели с предсказаниями других моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как пользоваться этим блокнотом\n",
    "Необходимо запустить все cells по порядку. Код сгенерирует веб-интерфейс для настройки моделей.\n",
    "\n",
    "# Библиотеки\n",
    "```\n",
    "$ cat requirements.txt\n",
    "jupyter==1.0.0\n",
    "matplotlib==3.3.2\n",
    "pandas==1.1.2\n",
    "scipy==1.5.2\n",
    "```\n",
    "\n",
    "# Данные\n",
    "## Источники\n",
    "- COVID-19: [Архив статистики от Яндекса](https://yandex.ru/covid19/stat) (собирает статистику со [стопкоронавирус.рф](https://стопкоронавирус.рф/information/))\n",
    "- Погода: [Архив фактической погоды от Росгидромедцентра](https://meteoinfo.ru/archive-pogoda) (доступны только последние 6 месяцев)\n",
    "\n",
    "## Структура директорий\n",
    "```\n",
    "./\n",
    "└── csv/\n",
    "    ├── activity/\n",
    "    │   ├─── info.csv\n",
    "    │   └─── yandex_activity_index.json\n",
    "    ├── weather/\n",
    "    │   ├─── info.csv\n",
    "    │   ├─── 1138.csv\n",
    "    │   ├─── 1486.csv\n",
    "    │   ├─── 1624.csv\n",
    "    │   ├─── 1700.csv\n",
    "    │   ├─── 1819.csv\n",
    "    │   ├─── 2223.csv\n",
    "    │   ├─── 2532.csv\n",
    "    │   ├─── 2718.csv\n",
    "    │   ├─── 1179.csv\n",
    "    │   ├─── 1498.csv\n",
    "    │   ├─── 1631.csv\n",
    "    │   ├─── 1705.csv\n",
    "    │   ├─── 1834.csv\n",
    "    │   ├─── 2262.csv\n",
    "    │   ├─── 2535.csv\n",
    "    │   ├─── 2740.csv\n",
    "    │   ├─── 1206.csv\n",
    "    │   ├─── 1557.csv\n",
    "    │   ├─── 1634.csv\n",
    "    │   ├─── 1707.csv\n",
    "    │   ├─── 1887.csv\n",
    "    │   ├─── 2292.csv\n",
    "    │   ├─── 2539.csv\n",
    "    │   ├─── 4994.csv\n",
    "    │   ├─── 1238.csv\n",
    "    │   ├─── 1567.csv\n",
    "    │   ├─── 1647.csv\n",
    "    │   ├─── 1709.csv\n",
    "    │   ├─── 1913.csv\n",
    "    │   ├─── 2322.csv\n",
    "    │   ├─── 2556.csv\n",
    "    │   ├─── 5019.csv\n",
    "    │   ├─── 1248.csv\n",
    "    │   ├─── 1581.csv\n",
    "    │   ├─── 1654.csv\n",
    "    │   ├─── 1732.csv\n",
    "    │   ├─── 1930.csv\n",
    "    │   ├─── 2430.csv\n",
    "    │   ├─── 2616.csv\n",
    "    │   ├─── 5031.csv\n",
    "    │   ├─── 1302.csv\n",
    "    │   ├─── 1590.csv\n",
    "    │   ├─── 1656.csv\n",
    "    │   ├─── 1754.csv\n",
    "    │   ├─── 1935.csv\n",
    "    │   ├─── 2446.csv\n",
    "    │   ├─── 2628.csv\n",
    "    │   ├─── info.csv\n",
    "    │   ├─── 1318.csv\n",
    "    │   ├─── 1599.csv\n",
    "    │   ├─── 1659.csv\n",
    "    │   ├─── 1759.csv\n",
    "    │   ├─── 1980.csv\n",
    "    │   ├─── 2450.csv\n",
    "    │   ├─── 2697.csv\n",
    "    │   ├─── 1401.csv\n",
    "    │   ├─── 1613.csv\n",
    "    │   ├─── 1679.csv\n",
    "    │   ├─── 1768.csv\n",
    "    │   ├─── 1987.csv\n",
    "    │   ├─── 2455.csv\n",
    "    │   ├─── 2700.csv\n",
    "    │   ├─── 1433.csv\n",
    "    │   ├─── 1614.csv\n",
    "    │   ├─── 1680.csv\n",
    "    │   ├─── 1803.csv\n",
    "    │   ├─── 2094.csv\n",
    "    │   ├─── 2496.csv\n",
    "    │   ├─── 2715.csv\n",
    "    │   ├─── 1452.csv\n",
    "    │   ├─── 1617.csv\n",
    "    │   ├─── 1685.csv\n",
    "    │   ├─── 1807.csv\n",
    "    │   ├─── 2107.csv\n",
    "    │   ├─── 2513.csv\n",
    "    │   ├─── 2716.csv\n",
    "    │   ├─── 1468.csv\n",
    "    │   ├─── 16186.csv\n",
    "    │   ├─── 1686.csv\n",
    "    │   ├─── 1815.csv\n",
    "    │   ├─── 2200.csv\n",
    "    │   ├─── 2530.csv\n",
    "    │   └─── 2717.csv\n",
    "    ├─── info.csv\n",
    "    ├─── RU_ALT.csv\n",
    "    ├─── RU_AMU.csv\n",
    "    ├─── RU_ARK.csv\n",
    "    ├─── RU_AST.csv\n",
    "    ├─── RU_BEL.csv\n",
    "    ├─── RU_BRY.csv\n",
    "    ├─── RU_VLA.csv\n",
    "    ├─── RU_VGG.csv\n",
    "    ├─── RU_VLG.csv\n",
    "    ├─── RU_VOR.csv\n",
    "    ├─── RU_YEV.csv\n",
    "    ├─── RU_ZAB.csv\n",
    "    ├─── RU_IVA.csv\n",
    "    ├─── RU_IRK.csv\n",
    "    ├─── RU_KB.csv\n",
    "    ├─── RU_KGD.csv\n",
    "    ├─── RU_KLU.csv\n",
    "    ├─── RU_KAM.csv\n",
    "    ├─── RU_KC.csv\n",
    "    ├─── RU_KEM.csv\n",
    "    ├─── RU_KIR.csv\n",
    "    ├─── RU_KOS.csv\n",
    "    ├─── RU_KDA.csv\n",
    "    ├─── RU_KYA.csv\n",
    "    ├─── RU_KGN.csv\n",
    "    ├─── RU_KRS.csv\n",
    "    ├─── RU_LEN.csv\n",
    "    ├─── RU_LIP.csv\n",
    "    ├─── RU_MAG.csv\n",
    "    ├─── RU_MOW.csv\n",
    "    ├─── RU_MOS.csv\n",
    "    ├─── RU_MUR.csv\n",
    "    ├─── RU_NEN.csv\n",
    "    ├─── RU_NIZ.csv\n",
    "    ├─── RU_NGR.csv\n",
    "    ├─── RU_NVS.csv\n",
    "    ├─── RU_OMS.csv\n",
    "    ├─── RU_ORE.csv\n",
    "    ├─── RU_ORL.csv\n",
    "    ├─── RU_PNZ.csv\n",
    "    ├─── RU_PER.csv\n",
    "    ├─── RU_PRI.csv\n",
    "    ├─── RU_PSK.csv\n",
    "    ├─── RU_AD.csv\n",
    "    ├─── RU_AL.csv\n",
    "    ├─── RU_BA.csv\n",
    "    ├─── RU_BU.csv\n",
    "    ├─── RU_DA.csv\n",
    "    ├─── RU_IN.csv\n",
    "    ├─── RU_KL.csv\n",
    "    ├─── RU_KR.csv\n",
    "    ├─── RU_KO.csv\n",
    "    ├─── RU_CR.csv\n",
    "    ├─── RU_ME.csv\n",
    "    ├─── RU_MO.csv\n",
    "    ├─── RU_SA.csv\n",
    "    ├─── RU_SE.csv\n",
    "    ├─── RU_TA.csv\n",
    "    ├─── RU_TY.csv\n",
    "    ├─── RU_KK.csv\n",
    "    ├─── RU_ROS.csv\n",
    "    ├─── RU_RYA.csv\n",
    "    ├─── RU_SAM.csv\n",
    "    ├─── RU_SPE.csv\n",
    "    ├─── RU_SAR.csv\n",
    "    ├─── RU_SAK.csv\n",
    "    ├─── RU_SVE.csv\n",
    "    ├─── RU_SMO.csv\n",
    "    ├─── RU_STA.csv\n",
    "    ├─── RU_TAM.csv\n",
    "    ├─── RU_TVE.csv\n",
    "    ├─── RU_TOM.csv\n",
    "    ├─── RU_TUL.csv\n",
    "    ├─── RU_TYU.csv\n",
    "    ├─── RU_UD.csv\n",
    "    ├─── RU_ULY.csv\n",
    "    ├─── RU_KHA.csv\n",
    "    ├─── RU_KHM.csv\n",
    "    ├─── RU_CHE.csv\n",
    "    ├─── RU_CE.csv\n",
    "    ├─── RU_CU.csv\n",
    "    ├─── RU_CHU.csv\n",
    "    ├─── RU_YAN.csv\n",
    "    └─── RU_YAR.csv\n",
    "```\n",
    "\n",
    "## Формат\n",
    "### COVID\n",
    "Файл `./csv/info.csv` содержит инофрмацию следующие поля:\n",
    "- `keys` -- ключи, по которым код обращается к файлам с статистикой по covid. Эти же ключи используются Яндексом и сайтом стопкоронавирус.рф.\n",
    "- `name` -- название населенного пункта. Кодом не используется.\n",
    "- `url` -- ссылка на json с данными яндекса.\n",
    "- `population` -- население города.\n",
    "\n",
    "\n",
    "Файлы `./csv/RU_*.csv` содержат статистику по covid для одного региона. Именная часть файла соответствует ключу из поля `key` файла `./csv/info.csv`. Файлы `./csv/RU_*.csv` содержат следующие поля:\n",
    "- `date` -- дата\n",
    "- `cases_total` -- общее количество случаев заражения\n",
    "- `cases_new` -- количество новых случаев заражения за день `date`\n",
    "- `deaths_total` -- общее количество летальных исходов\n",
    "- `deaths_new` -- количество новых летальных исходов за день `date`\n",
    "- `cured_total` -- общее количество выздоровевших\n",
    "- `cured_new` -- количество новых количество выздоровевших за день `date`\n",
    "\n",
    "\n",
    "### Погода\n",
    "Файл `./csv/weather/info.csv` содержит следующие поля:\n",
    "- `id` -- идентификатор города, по которому код обращается к файлам. Этот же идентификатор используется сайтом Росгидромедцентра.\n",
    "- `friendly_name` -- название региона. Данным кодом не используется.\n",
    "- `region_key` -- ключ региона, совпадающий с ключем из `./csv/info.csv`. Используется для сопоставления региона с файлами `./csv/weather/!(info.csv)` по идентификатору.\n",
    "\n",
    "\n",
    "Файлы `./csv/weather/!(info.csv)` содержат информацию о погоде для конкретного региона. Поля получены с сайта Росгидромедцентра автоматически. Поля, которые использует данный код:\n",
    "- `timestamp` -- время измерения в формате UNIX timestamp.\n",
    "- `Температура воздуха, °C`\n",
    "- `Относительная влажность, %`\n",
    "\n",
    "\n",
    "### Индекс активности Яндекс\n",
    "Файл `./csv/activity/info.csv` содержит следующие поля:\n",
    "- `region_key` -- ключ региона, совпадающий с ключем из `./csv/info.csv`.\n",
    "- `json_key` -- соотвествует названию города из региона region_key, для которго имеются данные, так же являюется ключюком\n",
    "в словаре `./csv/activity/yandex_activity_index.json`\n",
    "\n",
    "\n",
    "Файл `./csv/activity/yandex_activity_index.json` содержат информацию об индексе активности населения. Формат json-файла:  \n",
    "{ \n",
    "  \n",
    "     json_key: -- город,  \n",
    "         [\n",
    "             {\"date\" : дата1, \"value\" : value1},  \n",
    "             ...\n",
    "             {\"date\" : датаN, \"value\" : valueN}\n",
    "         ]  \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIR как линейная модель \n",
    "В данном ноутбуке изучается возможность применения модели $SIR$ для моделирования распространения Короновирсуной инфекции. Берется дискретная $SIR$ модель:  \n",
    "$(1) : \\begin{cases}\n",
    "    S_{t+1} = S_t - \\beta\\cfrac{S}{N} \\cdot I_t    \\\\\n",
    "    I_{t+1} = I_t + \\beta \\cfrac{S}{N}\\cdot I_t - \\gamma \\cdot I_t  \\\\ \n",
    "    R_{t+1} = R_{t} + \\gamma \\cdot I_t  \\\\  \n",
    "\\end{cases}\\\\$\n",
    "где каждый параметр зависит не от непрерывной величины - времени, а от дискретного номера дня $t$. \n",
    "\n",
    "Далее так же заменим $\\beta \\cfrac{S}{N}$ на $\\alpha$ и будем рассматривать $\\alpha$ и $\\gamma$ как линейные модели от известных данных или функций от известных данных в день, предшествующий прогнозу. К данным мы относим $S$, $I$, $R$, данные о погоде, населении и активности населения в конкретном регионе (те, что можно получить).\n",
    "\n",
    "Таким образом, модель прогноза получается линейной. В дальнейшем мы будем называть такую модель для краткости LDSIR (линейный дискретный SIR) и DSIR - просто дискретный SIR. Это можно явно увидеть, если сделать некоторые преобразования:\n",
    "\n",
    "$$V_t = \\begin{bmatrix} S_t & I_t & R_t \\end{bmatrix}^T $$  \n",
    "$$ V_{t} = V_t +I_t\\begin{bmatrix} -1 & 0 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}\\cdot\\begin{bmatrix}\\alpha_t \\\\ \\gamma_t \\end{bmatrix}$$  \n",
    "$$ \\Delta V = V_{T+1} - V_{T} $$  \n",
    "$$ \\Delta V_{t} =I_t\\begin{bmatrix} -1 & 0 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}\\cdot\\begin{bmatrix}\\alpha_t \\\\ \\gamma_t \\end{bmatrix}$$\n",
    "### Учтём, что  $\\alpha$  И $\\beta$ сами являются моделями:\n",
    "$ \\text{data}_\\alpha, \\text{data}_\\gamma$ - данные на которых мы обучаем линейную модель (факторы, которые мы учитываем; это данные для которых мы подбираем линейные коэффициенты)  \n",
    "$P_\\alpha = [P_{\\alpha1}, ..., P_{\\alpha q}]^T,\\; P_\\gamma = [P_{\\gamma1}, ..., P_{\\gamma k}]^T$ - параметры моделей.  \n",
    "$$\\alpha_t =  \\text{data}_\\alpha^T \\cdot P_\\alpha$$    \n",
    "$$\\gamma_t =  \\text{data}_\\gamma^T \\cdot P_\\gamma$$    \n",
    "$$\\Delta V_{t} =I_t\\begin{bmatrix} -1 \\\\ 1 \\\\ 0 \\end{bmatrix}\\cdot\\text{data}_\\alpha^T \\cdot P_\\alpha + I_t\\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix}\\cdot\\text{data}_\\gamma^T \\cdot P_\\gamma$$  \n",
    "$$\\Delta V_{t} =I_t\\begin{bmatrix}\\begin{bmatrix} -1 \\\\ 1 \\\\ 0 \\end{bmatrix}\\cdot\\text{data}_\\alpha^T & \\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix}\\cdot\\text{data}_\\gamma^T \\cdot \\end{bmatrix}\\cdot \\begin{bmatrix}P_\\alpha \\\\ P_\\gamma\\end{bmatrix}$$  \n",
    "    $$ \\Delta V_{t} = A_t\\cdot \\begin{bmatrix} P_\\alpha & P_\\gamma \\end{bmatrix}^T$$\n",
    "### Векторизация, когда у нас несколько дней, а не один:\n",
    "$ A = \\begin{bmatrix} A_1 & A_2 & ... A_N \\end{bmatrix}^T$   \n",
    "$ \\Delta V = \\begin{bmatrix} \\Delta V_1 & \\Delta V_2 & ... \\Delta V_N \\end{bmatrix}^T$   \n",
    "Тогда:  \n",
    "$$ \\Delta V = A\\cdot \\begin{bmatrix} P_\\alpha & P_\\gamma \\end{bmatrix}^T$$\n",
    "\n",
    "Подбор параметров происходит с помощью применения МНК к такой системе.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import lsq_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Класс, реализующий вышеописанную модель.\n",
    "class linear_SIR:\n",
    "    def __init__(self, alpha_formulas, gamma_formulas,\n",
    "                 init_alphas = None,\n",
    "                 init_gammas = None):\n",
    "        '''\n",
    "            alpha_formulas - str, формула модели alpha. Должна представлять из себя мономы (или полиномы),\n",
    "            разделенные пробелами. Каждый моном должен содержать константы или или известные величины.\n",
    "            Предполагается, что всем указанным величинам будут соответствовать столбцы в двумерном массиве\n",
    "            данных, который подается на вход методов predict, predict_n, fit, а соответствие между столбцами\n",
    "            и данными указывается в data_cols.\n",
    "            \n",
    "            gamma_formulas - str, формула модели gamma. Формат аналогичен alpha_formualas.\n",
    "            \n",
    "            init_alpha - значения параметров в модели для alpha\n",
    "            init_gammas - значения параметров в модели для gamma\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        self.a_formulas = alpha_formulas\n",
    "        self.g_formulas = gamma_formulas\n",
    "        \n",
    "        if init_alphas is not None:\n",
    "            self.alphas = init_alphas\n",
    "        else:\n",
    "            self.alphas = np.zeros(len(self.a_formulas))\n",
    "            \n",
    "        if init_gammas is not None:\n",
    "            self.gammas = init_gammas\n",
    "        else:\n",
    "            self.gammas = np.zeros(len(self.g_formulas))\n",
    "        \n",
    "\n",
    "    def predict(self, data, data_cols):\n",
    "        '''\n",
    "            Делает предсказание модели. \n",
    "            Формат входных данных:\n",
    "            data - np.array размера predict_case x len(data_cols)\n",
    "                каждая строка соответствует одному дню и для каждой строки модель возвращает \n",
    "                предсказание [S, I, R] для следующего дня.\n",
    "            data_cols - dict, ключи - наименования величин, значения - номер столбца, в котором\n",
    "            содержится данная величина\n",
    "            \n",
    "            return np.arra размера predict_case x 3. В каждой строке предсказание [S, I, R] для\n",
    "            соответствующего случая.\n",
    "        '''\n",
    "        A = self._build_data_matrix(data, data_cols)\n",
    "        \n",
    "        SIR_cols = [data_cols['S'], data_cols['I'], data_cols['R']]\n",
    "        \n",
    "        SIR = A @ np.hstack([self.alphas, self.gammas])[None].T\n",
    "        \n",
    "        SIR = data[:, SIR_cols]  + SIR.reshape(-1,3)\n",
    "        \n",
    "        return SIR.reshape(-1,3)\n",
    "    \n",
    "    \n",
    "    def predict_n(self, data_list, data_cols, n):\n",
    "        '''\n",
    "            предсказания на n дней вперед. \n",
    "            \n",
    "            data_list - list, каждый элемент которого есть np.array типа data из метода predict.\n",
    "            столбцы, соответствующие S, I, R для будущих дней могут быть любыми, они не используются\n",
    "            для предсказания (Обратите внимание, чтобы пользоваться этим методом, надо знать вспомогательные\n",
    "            данные (погоду и пр.) для будущих дней).\n",
    "            \n",
    "            data_cols - dict, ключи - наименования величин, значения - номер столбца, в котором\n",
    "            содержится данная величина\n",
    "            \n",
    "            return np.array n x predict_case x 3 - первая размерность отвечает за номер дня с момента\n",
    "            начала предсказания. При фиксированной значении первого индекса формат результата аналогичен\n",
    "            формату результата метода predict.\n",
    "        '''\n",
    "        SIR_cols = [data_cols['S'], data_cols['I'], data_cols['R']]\n",
    "\n",
    "        SIR_n_days = list(data_list[0][:, SIR_cols])\n",
    "        \n",
    "        for i in range(n):\n",
    "            tmp_data = data_list[i].copy()\n",
    "\n",
    "            tmp_data[:,SIR_cols] = SIR_n_days[-1]\n",
    "            \n",
    "            tmp_SIR = self.predict(tmp_data, data_cols)\n",
    "            \n",
    "            SIR_n_days.append(tmp_SIR)\n",
    "        \n",
    "        \n",
    "        return np.array(SIR_n_days[1:])\n",
    "            \n",
    "        \n",
    "    def fit(self, data, data_cols, method='LSM'):\n",
    "        '''\n",
    "            Подгонка параметров методом МНК\n",
    "\n",
    "            data, data_cols - формат аналогичен методу predict\n",
    "            data_cols должен содержать информацию об истинных значениях предсказываемых величин,\n",
    "            которые должны быть обозначены как aI, aS, aR\n",
    "\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        A = self._build_data_matrix(data, data_cols)\n",
    "        \n",
    "        SIR_cols = [data_cols['S'], data_cols['I'], data_cols['R']]\n",
    "        ANS_cols = [data_cols['aS'], data_cols['aI'], data_cols['aR']]\n",
    "        \n",
    "        b = (data[:, ANS_cols] - data[:, SIR_cols]).reshape(-1)\n",
    "        \n",
    "        #Solve Ax = b\n",
    "        self.fit_result = lsq_linear(A, b)\n",
    "        \n",
    "        self.alphas = self.fit_result.x[:len(self.alphas)]\n",
    "        self.gammas = self.fit_result.x[-len(self.gammas):]\n",
    " \n",
    "    \n",
    "    def _build_data_matrix(self, data, data_cols):\n",
    "        '''\n",
    "            Построение матрицы линейной модели (см. описание выше)\n",
    "        '''\n",
    "        \n",
    "       #alpha params part\n",
    "        al_matr = np.zeros((len(data), len(self.a_formulas)))\n",
    "        for i in range(len(self.a_formulas)):\n",
    "            s = self.a_formulas[i]\n",
    "            \n",
    "            for L in sorted(data_cols, key=lambda x: -len(x)):\n",
    "                s = s.replace(L, 'data[:,{0}]'.format(data_cols[L]))\n",
    "                \n",
    "            al_matr[:,i] = eval(s)\n",
    "        \n",
    "        #gamma params part\n",
    "        ga_matr = np.zeros((len(data), len(self.g_formulas)))     \n",
    "        for i in range(len(self.g_formulas)):\n",
    "            s = self.g_formulas[i]\n",
    "            \n",
    "            for L in sorted(data_cols, key=lambda x: -len(x)):\n",
    "                s = s.replace(L, 'data[:,{0}]'.format(data_cols[L]))\n",
    "                \n",
    "            ga_matr[:,i] = eval(s)\n",
    "        \n",
    "        # some matrix transfomation\n",
    "        al_vec = np.array([[-1,1, 0]]).T\n",
    "        al_matr = np.einsum('ij,cjk', al_vec, al_matr[:,np.newaxis,:])\n",
    "        al_matr = al_matr.reshape(-1, len(self.a_formulas))\n",
    "        \n",
    "        ga_vec = np.array([[0,-1, 1]]).T\n",
    "        ga_matr = np.einsum('ij,cjk', ga_vec, ga_matr[:,np.newaxis,:])\n",
    "        ga_matr = ga_matr.reshape(-1, len(self.g_formulas))\n",
    "        \n",
    "        \n",
    "        #Join the Parts\n",
    "        \n",
    "        triple_I = np.vstack((data[:, data_cols['I']],)*3).T.reshape(-1,1)\n",
    "        A = triple_I * np.hstack([al_matr, ga_matr]) \n",
    "        \n",
    "        return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение Датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Globals import region_population\n",
    "from Globals import region_friendly_name_inv as rfn_inv\n",
    "\n",
    "from Globals import get_weather_region_data\n",
    "from Globals import get_covid_region_data\n",
    "from Globals import get_region_activity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(regions): \n",
    "    #Вертикально стакаем данные по разным регионам в один датафрейм.\n",
    "    index_pointer = 0\n",
    "    for region in regions:\n",
    "        df_covid = get_covid_region_data(region)\n",
    "        df_weather = get_weather_region_data(region)[['time', 'date','Температура воздуха, °C', \n",
    "                                                    'Атмосферное давление на уровне станции, мм рт.ст.', \n",
    "                                                    'Относительная влажность, %' ]]\n",
    "        #усреднение данных погоды за день\n",
    "        df_weather = df_weather.groupby(['date']).mean()\n",
    "\n",
    "        df_activity = get_region_activity_data(region) \n",
    "        df_activity.set_index('date', inplace = True)\n",
    "\n",
    "        df_covid.set_index('date', inplace=True)\n",
    "        tmp_df = df_weather.join(df_covid)\n",
    "        tmp_df = tmp_df.join(df_activity)\n",
    "        \n",
    "        tmp_df['date'] = tmp_df.index\n",
    "        tmp_df['population'] = region_population[region] \n",
    "        \n",
    "        tmp_df_len = len(tmp_df)\n",
    "        \n",
    "        \n",
    "        tmp_df.set_index(pd.Series(range(index_pointer, index_pointer+tmp_df_len)))\n",
    "          \n",
    "        if index_pointer == 0:\n",
    "            df = tmp_df\n",
    "        else:\n",
    "            df = pd.concat([df,tmp_df], axis=0)\n",
    "        \n",
    "        index_pointer += tmp_df_len\n",
    "    \n",
    "    #Собираем из полученного датафрейма массив данных.\n",
    "    \n",
    "    #covid data\n",
    "    I = df['cases_total'] -  df['cured_total'] - df['deaths_total']\n",
    "    R = df['cured_total'] + df['deaths_total']\n",
    "    S = df['population'] - R - I\n",
    "\n",
    "    data = np.vstack((S,I,R, df['population'])).T\n",
    "    data = np.hstack((data[:-1,:], data[1:,:3]))\n",
    "\n",
    "\n",
    "    data_order = {'S' : 0, 'I' : 1, 'R' : 2, 'N' : 3, 'aS' : 4, 'aI' : 5, 'aR' : 6}\n",
    "\n",
    "    #weather\n",
    "    T = df['Температура воздуха, °C'].values[:-1,np.newaxis]\n",
    "    P = df['Атмосферное давление на уровне станции, мм рт.ст.'].values[:-1,np.newaxis]\n",
    "    H = df['Относительная влажность, %'].values[:-1, np.newaxis]\n",
    "    \n",
    "    data = np.hstack((data, T, P, H))\n",
    "    \n",
    "    data_order.update({'T' : 7, 'P' : 8, 'H' : 9})\n",
    "    \n",
    "    #activity\n",
    "    A = df['activity_rate'].values[:-1,np.newaxis]\n",
    "\n",
    "    data = np.hstack((data, A))\n",
    "    \n",
    "    data_order.update({'A' : 10})\n",
    "    \n",
    "    #for HIT\n",
    "    data = np.hstack((data,df['cases_total'].values[:-1,np.newaxis]))\n",
    "    data_order['TC'] = 11\n",
    "    \n",
    "    return data, data_order, df['date'].values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#График предсказаний и точных значений.\n",
    "def draw(l_SIR, data, data_order, dates, var, fork_day):\n",
    "    \n",
    "    SIR_pred = l_SIR.predict_n(list(data[fork_day:, np.newaxis,:]), data_order, len(data) - fork_day).reshape(-1,3)\n",
    "    I_pred = np.hstack((data[:fork_day, data_order['a'+var]], SIR_pred[:,data_order[var]]))\n",
    "    I_true = data[:, data_order['a'+var]]\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "\n",
    "    plt.plot(dates, I_pred, label = var+'_pred')\n",
    "    plt.plot(dates, I_true, label = var+'_true')\n",
    "    \n",
    "    minimum, maximum = min(np.min(I_pred), np.min(I_true)), max(np.max(I_pred),np.max(I_true))\n",
    "\n",
    "    plt.plot((dates[fork_day],)*2, (minimum,maximum), label='predicton begin day')\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel(var)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_pipline(fit_regions, \n",
    "                    predict_region, fork_date, var,\n",
    "                   a_formulas, g_formulas, fit_start_day, fit_end_day):\n",
    "    \n",
    "    if isinstance(fit_regions, str):\n",
    "        fit_regions = [fit_regions, ]\n",
    "    \n",
    "    #Получение данных по нужным регионам\n",
    "    data, data_order, dates = make_data(fit_regions)\n",
    "    \n",
    "    #Выбор данных за нужный период времени\n",
    "    within_timewindow = (dates >= pd.to_datetime(fit_start_day)) & (dates <= pd.to_datetime(fit_end_day))\n",
    "    data = data[within_timewindow]\n",
    "    dates = dates[within_timewindow]\n",
    "    \n",
    "    #Подбор коэффициентов\n",
    "    l_SIR = linear_SIR(a_formulas.split(' '), g_formulas.split(' '))\n",
    "    l_SIR.fit(data, data_order)\n",
    "    \n",
    "    #Предсказание для выбранного региона и сравнение предсказания с реальными значениями\n",
    "    data, data_order, dates = make_data([predict_region,])\n",
    "    fork_day = np.where(dates==pd.to_datetime(fork_date))[0][0]\n",
    "    \n",
    "    def gs(n):\n",
    "        if n>0:\n",
    "            return '+'\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "    print('Модели:')\n",
    "    print('alpha:', end=' ')\n",
    "    for i in range(len(l_SIR.alphas)):\n",
    "        print('{0}{1:.3e}·({2})'.format(gs(l_SIR.alphas[i]), l_SIR.alphas[i], l_SIR.a_formulas[i]), end='')\n",
    "    print('\\ngamma:', end=' ')\n",
    "    for i in range(len(l_SIR.gammas)):\n",
    "        print('{0}{1:.3e}·({2})'.format(gs(l_SIR.gammas[i]), l_SIR.gammas[i], l_SIR.g_formulas[i]), end='')\n",
    "    print('')\n",
    "    \n",
    "    draw(l_SIR, data, data_order, dates, var, fork_day) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from Globals import region_friendly_name\n",
    "from Globals import get_regions_with_activity_check\n",
    "def interactive_SIR():\n",
    "    \n",
    "    check_reg =get_regions_with_activity_check()\n",
    "    options = [region_friendly_name[reg] for reg in check_reg]\n",
    "    \n",
    "    Pred_region =  widgets.Dropdown(options=options,value='Москва',description='Predict_Region',disabled=False)\n",
    "    \n",
    "    Fit_regions = widgets.SelectMultiple(options=options, value = ['Москва',],\n",
    "                                        description='Fit_regions', disabled=False)\n",
    "    \n",
    "    alpha_model = widgets.Text(value=' '.join(['T*S/N', 'P*S/N', 'H*S/N', 'A']), description='alpha_model')\n",
    "    gamma_model = widgets.Text(value='1.', description='gamma_model')\n",
    "    \n",
    "    widgets.interact(general_pipline, fit_regions = Fit_regions, \n",
    "                    predict_region = Pred_region, fork_date='2020-09-01', var=['I', 'S','R'],\n",
    "                   a_formulas = alpha_model , g_formulas = gamma_model, \n",
    "                     fit_start_day ='2020-06-01', fit_end_day='2020-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Допустимые для использования парамеры в $\\alpha$ и $\\gamma$ моделях:\n",
    "$S, I, R$ - из модели SIR   \n",
    "$N$ - число житилей в Регионе  \n",
    "$P$ - давление  \n",
    "$T$ - температура  \n",
    "$H$ - влажность  \n",
    "$A$ - индекс активности от Яндекса  \n",
    "Параметры по погоде являются средними за день.\n",
    "\n",
    "При оценке модели, предполагается, что эти данные нам точно известны для будущих дней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_SIR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение с другими моделями\n",
    "Сравним модель LDSIR c TIR моделью (при $\\Delta=10$ и $\\gamma(t) = \\cfrac{1}{10}\\sum\\limits_{i=1}^{10}\\gamma(t-i)$ как на covidviward.com) и с простой версией SIR модели - DSIR (система (1) в самом начале ноутбука)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from HIT import HIT\n",
    "from Globals import get_covid_region_data\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comparsion(\n",
    "                    fitting_regions = ['Москва',],\n",
    "                    fit_start_day ='2020-06-01', fit_end_day='2020-09-30',\n",
    "                    predicting_region = 'Москва',\n",
    "                    start_predcting = '2020-09-01',\n",
    "                    compl_SIR_formula = 'T*S/N P*S/N H*S/N A',\n",
    "                    max_day_predict = 10):\n",
    "\n",
    "     \n",
    "    fitting_time_wind =(fit_start_day, fit_end_day)\n",
    "    \n",
    "    #Подготавливаем Данные для подгонки коэффциентов.\n",
    "    data, data_order, dates = make_data(fitting_regions)\n",
    "\n",
    "    within_timewindow = (dates >= pd.to_datetime(fitting_time_wind[0])) & (dates <= pd.to_datetime(fitting_time_wind[1]))\n",
    "    data = data[within_timewindow]\n",
    "    dates = dates[within_timewindow]\n",
    "\n",
    "    #Подготавливаем простой SIR\n",
    "    complic_SIRm = linear_SIR(compl_SIR_formula.split(), '1.'.split())\n",
    "    complic_SIRm.fit(data, data_order)\n",
    "\n",
    "    #Подготавливаем сложный SIR\n",
    "    simple_SIRm = linear_SIR('S/N'.split(), '1.'.split())\n",
    "    simple_SIRm.fit(data, data_order)\n",
    "\n",
    "    #Подготавливаем HIT\n",
    "\n",
    "\n",
    "    #Подготавливаем Данные для проноза.\n",
    "    data, data_order, dates = make_data([predicting_region,])\n",
    "\n",
    "    #Прогноз\n",
    "    day_id = np.where(dates == pd.to_datetime(start_predcting))[0][0]\n",
    "\n",
    "    complic_SIRm_pred = complic_SIRm.predict_n(\n",
    "                                    list(data[day_id-1:day_id+max_day_predict-1, np.newaxis,:]), \n",
    "                                    data_order, \n",
    "                                    max_day_predict\n",
    "                            ).reshape(-1,3)[:, 1:].sum(axis=1)\n",
    "\n",
    "    simple_SIRm_pred = simple_SIRm.predict_n(\n",
    "                                    list(data[day_id-1:day_id+max_day_predict-1, np.newaxis,:]), \n",
    "                                    data_order, \n",
    "                                    max_day_predict\n",
    "                            ).reshape(-1,3)[:, 1:].sum(axis=1)\n",
    "\n",
    "\n",
    "    HITm = HIT(dates[:day_id], data[:,data_order['TC']][:day_id])\n",
    "    HIT_dates, gammas = HITm.get_gamma()\n",
    "\n",
    "    avg_win = 10\n",
    "    for i in range(1,max_day_predict+1):\n",
    "\n",
    "        day = np.datetime64(pd.to_datetime(HIT_dates[-1])+timedelta(days=1))\n",
    "\n",
    "        HIT_dates = np.append(HIT_dates, day)\n",
    "        gammas = np.append(gammas, gammas[-avg_win:].mean())\n",
    "\n",
    "    HIT_dates = pd.to_datetime(HIT_dates)\n",
    "    HITm.update_T(HIT_dates[-max_day_predict:], gammas[-max_day_predict:])\n",
    "\n",
    "    HITm_pred = HITm.get_T()[-max_day_predict-1:][1][-max_day_predict:]\n",
    "\n",
    "\n",
    "    #Строим графики предсказаний\n",
    "    connect_point = data[:,data_order['TC']][day_id-1]\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    plt.plot(dates[day_id-12:day_id+max_day_predict],\n",
    "             data[:,data_order['TC']][day_id-12:day_id+max_day_predict], label='true_T')\n",
    "\n",
    "    plt.plot(dates[day_id-1:day_id+max_day_predict],\n",
    "             np.hstack((connect_point, complic_SIRm_pred)), label='LDSIR_T')\n",
    "\n",
    "    plt.plot(dates[day_id-1:day_id+max_day_predict],\n",
    "             np.hstack((connect_point, simple_SIRm_pred)), label='DSIR_T')\n",
    "\n",
    "    plt.plot(dates[day_id-1:day_id+max_day_predict],\n",
    "             np.hstack((connect_point, HITm_pred)), label='HIT_T')\n",
    "\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('Total cases of infection')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    #Cчитаем ошибку:\n",
    "    true_T = data[:,data_order['TC']][day_id:day_id+max_day_predict]\n",
    "    RMSE = lambda a,b: np.sqrt(((a - b) ** 2).mean())\n",
    "    print('{:<17}  {:<17}'.format('Алгоритм', 'RMSE ошибка T'))\n",
    "    print('{:<17}  {:<17}'.format('simple_SIR', np.round(RMSE(true_T, simple_SIRm_pred),2)))\n",
    "    print('{:<17}  {:<17}'.format('comple_SIR', np.round(RMSE(true_T, complic_SIRm_pred),2)))\n",
    "    print('{:<17}  {:<17}'.format('HIT', np.round(RMSE(true_T, HITm_pred),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from Globals import region_friendly_name\n",
    "from Globals import get_regions_with_activity_check\n",
    "def interactive_comparsion():\n",
    "    \n",
    "    check_reg =get_regions_with_activity_check()\n",
    "    options = [region_friendly_name[reg] for reg in check_reg]\n",
    "    \n",
    "    Pred_region =  widgets.Dropdown(options=options,value='Москва',description='Predict_Region',disabled=False)\n",
    "    \n",
    "    Fit_regions = widgets.SelectMultiple(options=options, value = ['Москва',],\n",
    "                                        description='Fit_regions', disabled=False)\n",
    "    \n",
    "    alpha_model = widgets.Text(value=' '.join(['T*S/N', 'P*S/N', 'H*S/N', 'A']), description='alpha_model')\n",
    "    gamma_model = widgets.Text(value='1.', description='gamma_model')\n",
    "    \n",
    "    max_day_predict = widgets.IntSlider(value=10,min=0,max=100,step=1,description='prediction days',\n",
    "                                    disabled=False,continuous_update=False,orientation='horizontal',\n",
    "                                    readout=True,readout_format='d')\n",
    "    \n",
    "    widgets.interact(make_comparsion,   fitting_regions = Fit_regions,\n",
    "                    predicting_region = Pred_region,\n",
    "                    start_predcting = '2020-09-01',\n",
    "                    max_day_predict = max_day_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive_comparsion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "*  Для модели LDSIR не получается найти такую линейную зависимость $\\alpha$ данных, чтобы она хорошо подходила для всех регионов.\n",
    "* Модель LDSIR которая использует известные нам данные (см. выше) работает хуже (имеет большую ошибку, если делает предсказания по данным, по которым она не обучалась), чем HIT (а зачастую хуже даже чем простой DSIR) и требует больше информации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
